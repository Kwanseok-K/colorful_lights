{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "200923_LightGBM_price.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMRkNX/3SpCjFR0kZBLrNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanseok-K/colorful_lights/blob/master/colorful_lights/code/Modeling/200923_LightGBM_price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGfzqH3fI2RU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Tgqh7MI5K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58db49c8-4b59-4a9a-fb92-d85789a1f087"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiVNoqSOI5G_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e50c9379-8b58-4e1c-c574-45b23ded1335"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/test/NS_2019.csv\", encoding= 'cp949')\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38300, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWJAuBaRI5Fb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e187d7ee-6797-436e-e124-0fa274f3b987"
      },
      "source": [
        "df = df.dropna()\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37368, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRN3zkdII5Bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "bea93daf-c73f-48ca-ba7f-1e19f6ac7313"
      },
      "source": [
        "df1 = df.drop(['p_code','m_code','date','hms', 'org_time', 'product','sale_m','ymd'],axis=1) \n",
        "df1 = pd.get_dummies(df1, columns=['month','day','wday','hour','cloud','order','max_order','before','add'])\n",
        "df1.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rain</th>\n",
              "      <th>temp</th>\n",
              "      <th>primetime</th>\n",
              "      <th>FlowSubway</th>\n",
              "      <th>FlowCar</th>\n",
              "      <th>duration</th>\n",
              "      <th>category</th>\n",
              "      <th>price</th>\n",
              "      <th>total</th>\n",
              "      <th>Y</th>\n",
              "      <th>holiday</th>\n",
              "      <th>stop</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Shop_Online</th>\n",
              "      <th>month_1</th>\n",
              "      <th>month_2</th>\n",
              "      <th>month_3</th>\n",
              "      <th>month_4</th>\n",
              "      <th>month_5</th>\n",
              "      <th>month_6</th>\n",
              "      <th>month_7</th>\n",
              "      <th>month_8</th>\n",
              "      <th>month_9</th>\n",
              "      <th>month_10</th>\n",
              "      <th>month_11</th>\n",
              "      <th>month_12</th>\n",
              "      <th>day_1</th>\n",
              "      <th>day_2</th>\n",
              "      <th>day_3</th>\n",
              "      <th>day_4</th>\n",
              "      <th>day_5</th>\n",
              "      <th>day_6</th>\n",
              "      <th>day_7</th>\n",
              "      <th>day_8</th>\n",
              "      <th>day_9</th>\n",
              "      <th>day_10</th>\n",
              "      <th>day_11</th>\n",
              "      <th>day_12</th>\n",
              "      <th>day_13</th>\n",
              "      <th>day_14</th>\n",
              "      <th>...</th>\n",
              "      <th>add_세탁기</th>\n",
              "      <th>add_소파</th>\n",
              "      <th>add_속옷_상의</th>\n",
              "      <th>add_속옷_세트</th>\n",
              "      <th>add_속옷_하의</th>\n",
              "      <th>add_수납</th>\n",
              "      <th>add_식기</th>\n",
              "      <th>add_신발</th>\n",
              "      <th>add_아우터</th>\n",
              "      <th>add_악세사리</th>\n",
              "      <th>add_안경류</th>\n",
              "      <th>add_에어컨</th>\n",
              "      <th>add_영양제</th>\n",
              "      <th>add_욕실</th>\n",
              "      <th>add_원피스</th>\n",
              "      <th>add_육류</th>\n",
              "      <th>add_음료</th>\n",
              "      <th>add_의류_상의</th>\n",
              "      <th>add_의류_세트</th>\n",
              "      <th>add_의류_하의</th>\n",
              "      <th>add_의류관리기</th>\n",
              "      <th>add_의자</th>\n",
              "      <th>add_작물</th>\n",
              "      <th>add_장롱</th>\n",
              "      <th>add_조리보조</th>\n",
              "      <th>add_주방</th>\n",
              "      <th>add_주방_기타</th>\n",
              "      <th>add_주방가전</th>\n",
              "      <th>add_책상</th>\n",
              "      <th>add_청소</th>\n",
              "      <th>add_청소기</th>\n",
              "      <th>add_침구</th>\n",
              "      <th>add_침대</th>\n",
              "      <th>add_카페트</th>\n",
              "      <th>add_커튼</th>\n",
              "      <th>add_케어</th>\n",
              "      <th>add_팬</th>\n",
              "      <th>add_포트</th>\n",
              "      <th>add_해산물</th>\n",
              "      <th>add_헤어</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.681818</td>\n",
              "      <td>0</td>\n",
              "      <td>115735</td>\n",
              "      <td>152109</td>\n",
              "      <td>20.0</td>\n",
              "      <td>의류</td>\n",
              "      <td>39900.0</td>\n",
              "      <td>2099000.0</td>\n",
              "      <td>2.630326</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.02</td>\n",
              "      <td>1.0946</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.681818</td>\n",
              "      <td>0</td>\n",
              "      <td>115735</td>\n",
              "      <td>152109</td>\n",
              "      <td>20.0</td>\n",
              "      <td>의류</td>\n",
              "      <td>39900.0</td>\n",
              "      <td>4371000.0</td>\n",
              "      <td>5.477444</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.02</td>\n",
              "      <td>1.0946</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.681818</td>\n",
              "      <td>0</td>\n",
              "      <td>115735</td>\n",
              "      <td>152109</td>\n",
              "      <td>20.0</td>\n",
              "      <td>의류</td>\n",
              "      <td>39900.0</td>\n",
              "      <td>3262000.0</td>\n",
              "      <td>4.087719</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.02</td>\n",
              "      <td>1.0946</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.681818</td>\n",
              "      <td>0</td>\n",
              "      <td>115735</td>\n",
              "      <td>152109</td>\n",
              "      <td>20.0</td>\n",
              "      <td>의류</td>\n",
              "      <td>39900.0</td>\n",
              "      <td>6955000.0</td>\n",
              "      <td>8.715539</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.02</td>\n",
              "      <td>1.0946</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.681818</td>\n",
              "      <td>0</td>\n",
              "      <td>115735</td>\n",
              "      <td>152109</td>\n",
              "      <td>20.0</td>\n",
              "      <td>의류</td>\n",
              "      <td>39900.0</td>\n",
              "      <td>6672000.0</td>\n",
              "      <td>8.360902</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>104.02</td>\n",
              "      <td>1.0946</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 180 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   rain      temp  primetime  FlowSubway  ...  add_팬  add_포트 add_해산물  add_헤어\n",
              "0   0.1 -1.681818          0      115735  ...      0       0       0       0\n",
              "1   0.1 -1.681818          0      115735  ...      0       0       0       0\n",
              "2   0.1 -1.681818          0      115735  ...      0       0       0       0\n",
              "3   0.1 -1.681818          0      115735  ...      0       0       0       0\n",
              "4   0.1 -1.681818          0      115735  ...      0       0       0       0\n",
              "\n",
              "[5 rows x 180 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQqVjASMI4_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "df1=df1.assign(class_=\"\")\n",
        "splitt = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=2020)\n",
        "grp = df['category']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlWL3jPcI48N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for train_index, test_index in splitt.split(df1, grp):\n",
        "    strat_train = df1.iloc[train_index,]\n",
        "    strat_test = df1.iloc[test_index,]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rhm_JA9I46A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리 더미화 \n",
        "strat_train = pd.get_dummies(strat_train, columns=['category'])\n",
        "strat_test = pd.get_dummies(strat_test,  columns=['category'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxHS2kTSI420",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "185f87f3-1a2d-4b58-86c9-1f08beffd5b0"
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.16.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp36-none-any.whl size=11685 sha256=38b053d9656096e5b3f1e95a2dfdd50f3d4670c9e57195b5e6bed4535e2dd61d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTyOl8YwSv-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a4e6391c-0816-4588-9553-ad22053ea2b9"
      },
      "source": [
        "print(strat_train.shape)\n",
        "print(strat_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28026, 191)\n",
            "(9342, 191)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-7iOLZrI4z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q1=strat_train['price'].quantile(q=0.25, interpolation='nearest')\n",
        "q3=strat_train['price'].quantile(q=0.75, interpolation='nearest')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcgnP4peI4xI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "e18a1713-1474-4773-95e3-794abb461d66"
      },
      "source": [
        "strat_train['class_'].loc[strat_train['price'] <q1]=1\n",
        "strat_train['class_'].loc[(strat_train['price']>=q1) & (strat_train['price'] <q3)]=2 \n",
        "strat_train['class_'].loc[strat_train['price']>=q3]=3\n",
        "\n",
        "strat_test['class_'].loc[strat_test['price'] <q1]=1\n",
        "strat_test['class_'].loc[(strat_test['price']>=q1) & (strat_test['price'] <q3)]=2 \n",
        "strat_test['class_'].loc[strat_test['price']>=q3]=3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFhwEybmm9WL",
        "colab_type": "text"
      },
      "source": [
        "Outlier 제거 코드(일단 안 씀)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y9adzKEI4te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_outlier(data, column):\n",
        "  fraud_column_data = data[column]\n",
        "  quan_25 = np.percentile(fraud_column_data.values, 25)\n",
        "  quan_75 = np.percentile(fraud_column_data.values, 75)\n",
        "\n",
        "  iqr = (quan_75-quan_25) * 3\n",
        "  lowest = quan_25 - iqr\n",
        "  highest = quan_75 + iqr\n",
        "  outlier_index = fraud_column_data[(fraud_column_data<lowest)|(fraud_column_data>highest)].index\n",
        "  data.drop(outlier_index, axis = 0, inplace = True)\n",
        "  print(data.shape)\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcVY83jI4qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strat_train_copy = remove_outlier(strat_train, 'Y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOAxA8xJQqNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strat_train = remove_outlier(strat_train , 'Y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs4h0XnXZgCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9QWHJKeNBAv",
        "colab_type": "text"
      },
      "source": [
        "Low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guvoxLbBM6Dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "low_train=strat_train[strat_train['class_']==1]\n",
        "low_test=strat_test[strat_test['class_']==1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtmmKGbfOC61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "low_train = low_train.drop(['class_','total'],axis =1)\n",
        "low_test = low_test.drop(['class_','total'],axis =1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jl_gmY2nYeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "low_train = low_train[low_train.Y!=0]\n",
        "low_test = low_test[low_test.Y!=0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wtLTQNKnllr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "61e01d25-9f6c-4bca-a915-bd1843eb8f5b"
      },
      "source": [
        "X_train = low_train[low_train.columns.difference(['Y'])]\n",
        "y_train = np.log(low_train['Y'])\n",
        "X_test = low_test[low_test.columns.difference(['Y'])]\n",
        "y_test = np.log(low_test['Y'])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6097, 188) (6097,)\n",
            "(2011, 188) (2011,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ETjS9GoSIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRBlFGyCNSzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OiS0depNOqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " pbounds = {'learning_rate' : (0.01, 0.3),\n",
        "            'n_estimators': (2000, 4000),\n",
        "            'num_leaves' : (30, 150),\n",
        "            'max_depth' : (-1, 15),\n",
        "            'colsample_bytree' : (0.7, 1),\n",
        "            'subsample' : (0.5, 0.8), \n",
        "            'min_child_samples': (20, 100),\n",
        "            'subsample_for_bin': (20000, 100000),\n",
        "            'reg_lambda' : (0.5,0.9), 'reg_alpha': (0.5,1.0)}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR8ri4LWTQ82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lgb_hyper_param(learning_rate, n_estimators, max_depth, \n",
        "                        subsample, colsample_bytree, num_leaves, \n",
        "                        min_child_samples, subsample_for_bin,\n",
        "                      reg_alpha, reg_lambda):\n",
        "    \n",
        "    max_depth = int(max_depth)\n",
        "    n_estimators = int(n_estimators)\n",
        "    min_child_samples = int(min_child_samples)\n",
        "    num_leaves = int(num_leaves)\n",
        "    subsample_for_bin = int(subsample_for_bin)\n",
        "\n",
        "    \n",
        "    model = lgb.LGBMRegressor(learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                     max_depth=max_depth, subsample= subsample,\n",
        "                     colsample_bytree=colsample_bytree, num_leaves = num_leaves,\n",
        "                    min_child_samples=min_child_samples, subsample_for_bin=subsample_for_bin,\n",
        "                    reg_alpha=reg_alpha, reg_lambda = reg_lambda)\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    #mse = mean_squared_error(y_test, y_pred)\n",
        "    #r2 = r2_score(y_test, y_pred)\n",
        "    mape =  - mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    return mape"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC-JmyO-TseG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = BayesianOptimization(\n",
        "    f=lgb_hyper_param,\n",
        "    pbounds=pbounds,\n",
        "    random_state=2020,\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv9O0M9dTwYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "3ad60bab-636d-4315-8932-45cedc75f922"
      },
      "source": [
        "optimizer.maximize(init_points=3, n_iter=30, acq='ei')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample | subsam... |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-11.8    \u001b[0m | \u001b[0m 0.7423  \u001b[0m | \u001b[0m 0.2296  \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 48.45   \u001b[0m | \u001b[0m 2.682e+0\u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.6086  \u001b[0m | \u001b[0m 0.7246  \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 4.558e+0\u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-11.83   \u001b[0m | \u001b[0m 0.986   \u001b[0m | \u001b[0m 0.04983 \u001b[0m | \u001b[0m 8.111   \u001b[0m | \u001b[0m 98.05   \u001b[0m | \u001b[0m 3.007e+0\u001b[0m | \u001b[0m 110.1   \u001b[0m | \u001b[0m 0.5171  \u001b[0m | \u001b[0m 0.6824  \u001b[0m | \u001b[0m 0.5468  \u001b[0m | \u001b[0m 5.808e+0\u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-11.24   \u001b[0m | \u001b[95m 0.7509  \u001b[0m | \u001b[95m 0.2699  \u001b[0m | \u001b[95m 4.974   \u001b[0m | \u001b[95m 50.38   \u001b[0m | \u001b[95m 3.717e+0\u001b[0m | \u001b[95m 107.5   \u001b[0m | \u001b[95m 0.7917  \u001b[0m | \u001b[95m 0.7673  \u001b[0m | \u001b[95m 0.5533  \u001b[0m | \u001b[95m 8.794e+0\u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-11.68   \u001b[0m | \u001b[0m 0.8327  \u001b[0m | \u001b[0m 0.2511  \u001b[0m | \u001b[0m 11.22   \u001b[0m | \u001b[0m 93.58   \u001b[0m | \u001b[0m 2.141e+0\u001b[0m | \u001b[0m 48.74   \u001b[0m | \u001b[0m 0.8184  \u001b[0m | \u001b[0m 0.7223  \u001b[0m | \u001b[0m 0.5576  \u001b[0m | \u001b[0m 5.405e+0\u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-11.73   \u001b[0m | \u001b[0m 0.854   \u001b[0m | \u001b[0m 0.08812 \u001b[0m | \u001b[0m 8.584   \u001b[0m | \u001b[0m 37.61   \u001b[0m | \u001b[0m 2.602e+0\u001b[0m | \u001b[0m 35.81   \u001b[0m | \u001b[0m 0.7822  \u001b[0m | \u001b[0m 0.8744  \u001b[0m | \u001b[0m 0.7409  \u001b[0m | \u001b[0m 7.578e+0\u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-11.77   \u001b[0m | \u001b[0m 0.8352  \u001b[0m | \u001b[0m 0.257   \u001b[0m | \u001b[0m 11.85   \u001b[0m | \u001b[0m 97.44   \u001b[0m | \u001b[0m 2.157e+0\u001b[0m | \u001b[0m 94.68   \u001b[0m | \u001b[0m 0.8611  \u001b[0m | \u001b[0m 0.7762  \u001b[0m | \u001b[0m 0.7502  \u001b[0m | \u001b[0m 9.999e+0\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-12.1    \u001b[0m | \u001b[0m 0.84    \u001b[0m | \u001b[0m 0.198   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 62.81   \u001b[0m | \u001b[0m 2.064e+0\u001b[0m | \u001b[0m 95.55   \u001b[0m | \u001b[0m 0.8911  \u001b[0m | \u001b[0m 0.7079  \u001b[0m | \u001b[0m 0.6503  \u001b[0m | \u001b[0m 2.001e+0\u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-12.18   \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 0.03541 \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 89.92   \u001b[0m | \u001b[0m 2.473e+0\u001b[0m | \u001b[0m 84.35   \u001b[0m | \u001b[0m 0.9776  \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.7472  \u001b[0m | \u001b[0m 4.184e+0\u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-11.55   \u001b[0m | \u001b[0m 0.9729  \u001b[0m | \u001b[0m 0.2943  \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 84.07   \u001b[0m | \u001b[0m 2.48e+03\u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 0.584   \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 0.6336  \u001b[0m | \u001b[0m 2.586e+0\u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-11.88   \u001b[0m | \u001b[0m 0.8803  \u001b[0m | \u001b[0m 0.05976 \u001b[0m | \u001b[0m-0.3307  \u001b[0m | \u001b[0m 38.82   \u001b[0m | \u001b[0m 3.571e+0\u001b[0m | \u001b[0m 68.47   \u001b[0m | \u001b[0m 0.6362  \u001b[0m | \u001b[0m 0.6211  \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 7.09e+04\u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-11.63   \u001b[0m | \u001b[0m 0.7833  \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 4.855   \u001b[0m | \u001b[0m 88.83   \u001b[0m | \u001b[0m 3.171e+0\u001b[0m | \u001b[0m 89.62   \u001b[0m | \u001b[0m 0.8894  \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.5127  \u001b[0m | \u001b[0m 3.123e+0\u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-12.12   \u001b[0m | \u001b[0m 0.987   \u001b[0m | \u001b[0m 0.2561  \u001b[0m | \u001b[0m 9.129   \u001b[0m | \u001b[0m 39.99   \u001b[0m | \u001b[0m 2.003e+0\u001b[0m | \u001b[0m 113.8   \u001b[0m | \u001b[0m 0.9152  \u001b[0m | \u001b[0m 0.7546  \u001b[0m | \u001b[0m 0.6019  \u001b[0m | \u001b[0m 8.69e+04\u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-11.84   \u001b[0m | \u001b[0m 0.7209  \u001b[0m | \u001b[0m 0.2446  \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 50.07   \u001b[0m | \u001b[0m 2.398e+0\u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 0.7949  \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 2.519e+0\u001b[0m |\n",
            "| \u001b[95m 14      \u001b[0m | \u001b[95m-11.19   \u001b[0m | \u001b[95m 0.7     \u001b[0m | \u001b[95m 0.2028  \u001b[0m | \u001b[95m 8.237   \u001b[0m | \u001b[95m 79.78   \u001b[0m | \u001b[95m 4e+03   \u001b[0m | \u001b[95m 128.1   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.7704  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 9.07e+04\u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-12.72   \u001b[0m | \u001b[0m 0.7822  \u001b[0m | \u001b[0m 0.01922 \u001b[0m | \u001b[0m 11.24   \u001b[0m | \u001b[0m 94.35   \u001b[0m | \u001b[0m 3.948e+0\u001b[0m | \u001b[0m 72.28   \u001b[0m | \u001b[0m 0.9066  \u001b[0m | \u001b[0m 0.5619  \u001b[0m | \u001b[0m 0.6231  \u001b[0m | \u001b[0m 2.791e+0\u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-12.02   \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 10.14   \u001b[0m | \u001b[0m 70.95   \u001b[0m | \u001b[0m 2.619e+0\u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 0.7303  \u001b[0m | \u001b[0m 0.5991  \u001b[0m | \u001b[0m 2.94e+04\u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-11.76   \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.2109  \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 43.13   \u001b[0m | \u001b[0m 3.66e+03\u001b[0m | \u001b[0m 41.2    \u001b[0m | \u001b[0m 0.9922  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 8.717e+0\u001b[0m |\n",
            "| \u001b[95m 18      \u001b[0m | \u001b[95m-10.86   \u001b[0m | \u001b[95m 0.8844  \u001b[0m | \u001b[95m 0.2417  \u001b[0m | \u001b[95m 4.614   \u001b[0m | \u001b[95m 40.71   \u001b[0m | \u001b[95m 3.926e+0\u001b[0m | \u001b[95m 132.5   \u001b[0m | \u001b[95m 0.5987  \u001b[0m | \u001b[95m 0.5173  \u001b[0m | \u001b[95m 0.653   \u001b[0m | \u001b[95m 8.922e+0\u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-11.49   \u001b[0m | \u001b[0m 0.9234  \u001b[0m | \u001b[0m 0.2266  \u001b[0m | \u001b[0m 9.019   \u001b[0m | \u001b[0m 96.99   \u001b[0m | \u001b[0m 2.045e+0\u001b[0m | \u001b[0m 132.2   \u001b[0m | \u001b[0m 0.5844  \u001b[0m | \u001b[0m 0.7433  \u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 3.484e+0\u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-12.99   \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.01533 \u001b[0m | \u001b[0m 9.644   \u001b[0m | \u001b[0m 60.55   \u001b[0m | \u001b[0m 3.211e+0\u001b[0m | \u001b[0m 91.76   \u001b[0m | \u001b[0m 0.7785  \u001b[0m | \u001b[0m 0.7679  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 4.889e+0\u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-12.0    \u001b[0m | \u001b[0m 0.911   \u001b[0m | \u001b[0m 0.202   \u001b[0m | \u001b[0m-0.7607  \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 3.644e+0\u001b[0m | \u001b[0m 122.6   \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 8.2e+04 \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-11.87   \u001b[0m | \u001b[0m 0.7761  \u001b[0m | \u001b[0m 0.1425  \u001b[0m | \u001b[0m 10.84   \u001b[0m | \u001b[0m 47.43   \u001b[0m | \u001b[0m 2.068e+0\u001b[0m | \u001b[0m 108.8   \u001b[0m | \u001b[0m 0.5207  \u001b[0m | \u001b[0m 0.7148  \u001b[0m | \u001b[0m 0.6988  \u001b[0m | \u001b[0m 9e+04   \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-21.9    \u001b[0m | \u001b[0m 0.8289  \u001b[0m | \u001b[0m 0.02396 \u001b[0m | \u001b[0m 1.564   \u001b[0m | \u001b[0m 68.99   \u001b[0m | \u001b[0m 2.036e+0\u001b[0m | \u001b[0m 130.4   \u001b[0m | \u001b[0m 0.8843  \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 0.6171  \u001b[0m | \u001b[0m 6.437e+0\u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-11.31   \u001b[0m | \u001b[0m 0.884   \u001b[0m | \u001b[0m 0.1536  \u001b[0m | \u001b[0m 9.529   \u001b[0m | \u001b[0m 91.21   \u001b[0m | \u001b[0m 3.924e+0\u001b[0m | \u001b[0m 141.3   \u001b[0m | \u001b[0m 0.6205  \u001b[0m | \u001b[0m 0.5781  \u001b[0m | \u001b[0m 0.5073  \u001b[0m | \u001b[0m 3.376e+0\u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-11.76   \u001b[0m | \u001b[0m 0.7288  \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 13.84   \u001b[0m | \u001b[0m 78.77   \u001b[0m | \u001b[0m 2.716e+0\u001b[0m | \u001b[0m 81.57   \u001b[0m | \u001b[0m 0.8412  \u001b[0m | \u001b[0m 0.6944  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 9.575e+0\u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-12.22   \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.1211  \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 44.13   \u001b[0m | \u001b[0m 3.993e+0\u001b[0m | \u001b[0m 85.87   \u001b[0m | \u001b[0m 0.9427  \u001b[0m | \u001b[0m 0.8782  \u001b[0m | \u001b[0m 0.7693  \u001b[0m | \u001b[0m 3.66e+04\u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-11.82   \u001b[0m | \u001b[0m 0.7899  \u001b[0m | \u001b[0m 0.256   \u001b[0m | \u001b[0m 10.48   \u001b[0m | \u001b[0m 83.04   \u001b[0m | \u001b[0m 2.009e+0\u001b[0m | \u001b[0m 53.15   \u001b[0m | \u001b[0m 0.8743  \u001b[0m | \u001b[0m 0.8091  \u001b[0m | \u001b[0m 0.6037  \u001b[0m | \u001b[0m 3.298e+0\u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-11.68   \u001b[0m | \u001b[0m 0.8953  \u001b[0m | \u001b[0m 0.104   \u001b[0m | \u001b[0m 4.852   \u001b[0m | \u001b[0m 98.23   \u001b[0m | \u001b[0m 3.897e+0\u001b[0m | \u001b[0m 74.42   \u001b[0m | \u001b[0m 0.6816  \u001b[0m | \u001b[0m 0.813   \u001b[0m | \u001b[0m 0.6918  \u001b[0m | \u001b[0m 5.569e+0\u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-11.25   \u001b[0m | \u001b[0m 0.7409  \u001b[0m | \u001b[0m 0.2943  \u001b[0m | \u001b[0m 8.914   \u001b[0m | \u001b[0m 64.19   \u001b[0m | \u001b[0m 3.981e+0\u001b[0m | \u001b[0m 118.3   \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 0.5481  \u001b[0m | \u001b[0m 7.344e+0\u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-11.72   \u001b[0m | \u001b[0m 0.8676  \u001b[0m | \u001b[0m 0.0723  \u001b[0m | \u001b[0m 7.139   \u001b[0m | \u001b[0m 40.67   \u001b[0m | \u001b[0m 2.02e+03\u001b[0m | \u001b[0m 109.5   \u001b[0m | \u001b[0m 0.7443  \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 7.312e+0\u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-11.88   \u001b[0m | \u001b[0m 0.7171  \u001b[0m | \u001b[0m 0.2345  \u001b[0m | \u001b[0m 3.395   \u001b[0m | \u001b[0m 26.44   \u001b[0m | \u001b[0m 3.088e+0\u001b[0m | \u001b[0m 119.9   \u001b[0m | \u001b[0m 0.8607  \u001b[0m | \u001b[0m 0.8311  \u001b[0m | \u001b[0m 0.7201  \u001b[0m | \u001b[0m 4.575e+0\u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-11.83   \u001b[0m | \u001b[0m 0.7372  \u001b[0m | \u001b[0m 0.2142  \u001b[0m | \u001b[0m 7.928   \u001b[0m | \u001b[0m 22.05   \u001b[0m | \u001b[0m 2.217e+0\u001b[0m | \u001b[0m 140.6   \u001b[0m | \u001b[0m 0.9294  \u001b[0m | \u001b[0m 0.5706  \u001b[0m | \u001b[0m 0.7875  \u001b[0m | \u001b[0m 2.888e+0\u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-12.29   \u001b[0m | \u001b[0m 0.8631  \u001b[0m | \u001b[0m 0.2588  \u001b[0m | \u001b[0m 8.093   \u001b[0m | \u001b[0m 32.0    \u001b[0m | \u001b[0m 3.996e+0\u001b[0m | \u001b[0m 62.73   \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 0.6315  \u001b[0m | \u001b[0m 0.5141  \u001b[0m | \u001b[0m 7.831e+0\u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m-11.4    \u001b[0m | \u001b[0m 0.7756  \u001b[0m | \u001b[0m 0.2315  \u001b[0m | \u001b[0m 4.616   \u001b[0m | \u001b[0m 43.81   \u001b[0m | \u001b[0m 3.986e+0\u001b[0m | \u001b[0m 49.37   \u001b[0m | \u001b[0m 0.5605  \u001b[0m | \u001b[0m 0.6823  \u001b[0m | \u001b[0m 0.5533  \u001b[0m | \u001b[0m 9.833e+0\u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m-11.69   \u001b[0m | \u001b[0m 0.7263  \u001b[0m | \u001b[0m 0.1585  \u001b[0m | \u001b[0m 14.15   \u001b[0m | \u001b[0m 89.67   \u001b[0m | \u001b[0m 2.023e+0\u001b[0m | \u001b[0m 124.7   \u001b[0m | \u001b[0m 0.7962  \u001b[0m | \u001b[0m 0.7733  \u001b[0m | \u001b[0m 0.6777  \u001b[0m | \u001b[0m 5.653e+0\u001b[0m |\n",
            "=================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wemrzzJoIwF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "aa0497df-b46f-4994-b3bd-0ef43c1865f2"
      },
      "source": [
        "optimizer.max"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'colsample_bytree': 0.8844377955345387,\n",
              "  'learning_rate': 0.24173636670316062,\n",
              "  'max_depth': 4.61414975399704,\n",
              "  'min_child_samples': 40.70564222703128,\n",
              "  'n_estimators': 3926.237273568207,\n",
              "  'num_leaves': 132.46653989514022,\n",
              "  'reg_alpha': 0.5987416135557838,\n",
              "  'reg_lambda': 0.5173263271083249,\n",
              "  'subsample': 0.6529860560241294,\n",
              "  'subsample_for_bin': 89220.95362523853},\n",
              " 'target': -10.860466242303177}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqNHZDYo2_O",
        "colab_type": "text"
      },
      "source": [
        "{'params': {'colsample_bytree': 0.8844377955345387,\n",
        "  'learning_rate': 0.24173636670316062,\n",
        "  'max_depth': 4.61414975399704,\n",
        "  'min_child_samples': 40.70564222703128,\n",
        "  'n_estimators': 3926.237273568207,\n",
        "  'num_leaves': 132.46653989514022,\n",
        "  'reg_alpha': 0.5987416135557838,\n",
        "  'reg_lambda': 0.5173263271083249,\n",
        "  'subsample': 0.6529860560241294,\n",
        "  'subsample_for_bin': 89220.95362523853},\n",
        " 'target': -10.860466242303177}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxaH9YzkoI1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.LGBMRegressor(learning_rate=optimizer.max['params']['learning_rate'], \n",
        "                          n_estimators=int(optimizer.max['params']['n_estimators']),\n",
        "                          num_leaves = int(optimizer.max['params']['num_leaves']),\n",
        "                          subsample = optimizer.max['params']['subsample'],\n",
        "                          subsample_for_bin = int(optimizer.max['params']['subsample_for_bin']), \n",
        "                          random_state=2020,\n",
        "                          colsample_bytree = optimizer.max['params']['colsample_bytree'],\n",
        "                          min_child_samples = int(optimizer.max['params']['min_child_samples']),\n",
        "                          max_depth = int(optimizer.max['params']['max_depth']),\n",
        "                          reg_alpha = optimizer.max['params']['reg_alpha'], \n",
        "                          reg_lambda = optimizer.max['params']['reg_lambda'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOfUwFUIoIsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "lgbm_pred = model.predict(X_test)\n",
        "lgbm_pred_train = model.predict(X_train)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM-nB903oNyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5966b29e-62ff-448a-cb61-91b9dae75c70"
      },
      "source": [
        "mape_train = mean_absolute_percentage_error(np.exp(y_train), np.exp(lgbm_pred_train))\n",
        "mape_test = mean_absolute_percentage_error(np.exp(y_test), np.exp(lgbm_pred))\n",
        "\n",
        "print('MAPE => train: %.2f,   test: %.2f' %(mape_train, mape_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE => train: 14.10,   test: 29.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v45OKAYNTwDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdSukhajpkPx",
        "colab_type": "text"
      },
      "source": [
        "Medium"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hobm5vgPYbOW",
        "colab": {}
      },
      "source": [
        "med_train=strat_train[strat_train['class_']==2]\n",
        "med_test=strat_test[strat_test['class_']==2]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP1O_N0DZH-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "med_train = med_train.drop(['class_','total'],axis =1)\n",
        "med_test = med_test.drop(['class_','total'],axis =1)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWheiaZsqTsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "med_train = med_train[med_train.Y!=0]\n",
        "med_test = med_test[med_test.Y!=0]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UTD9StrrYbOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ce562b43-9a46-4d69-ad56-9618f9f12fff"
      },
      "source": [
        "print(med_train.shape)\n",
        "print(med_test.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14791, 189)\n",
            "(4975, 189)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek_OqrlLqGhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "77bdc19e-81cc-46b6-c664-995c8ff2ee2d"
      },
      "source": [
        "X_train = med_train[med_train.columns.difference(['Y'])]\n",
        "y_train = np.log(med_train['Y'])\n",
        "X_test = med_test[med_test.columns.difference(['Y'])]\n",
        "y_test = np.log(med_test['Y'])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14791, 188) (14791,)\n",
            "(4975, 188) (4975,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mTNgYVrqg8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " pbounds1 = {'learning_rate' : (0.01, 0.3),\n",
        "            'n_estimators': (2000, 4000),\n",
        "            'num_leaves' : (30, 150),\n",
        "            'max_depth' : (-1, 15),\n",
        "            'colsample_bytree' : (0.7, 1),\n",
        "            'subsample' : (0.5, 0.8), \n",
        "            'min_child_samples': (20, 100),\n",
        "            'subsample_for_bin': (20000, 100000),\n",
        "            'reg_lambda' : (0.5,0.9), 'reg_alpha': (0.5,1.0)}"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FdEEz3VqoY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lgb_hyper_param1(learning_rate, n_estimators, max_depth, \n",
        "                        subsample, colsample_bytree, num_leaves, \n",
        "                        min_child_samples, subsample_for_bin,\n",
        "                      reg_alpha, reg_lambda):\n",
        "    \n",
        "    max_depth = int(max_depth)\n",
        "    n_estimators = int(n_estimators)\n",
        "    min_child_samples = int(min_child_samples)\n",
        "    num_leaves = int(num_leaves)\n",
        "    subsample_for_bin = int(subsample_for_bin)\n",
        "\n",
        "    \n",
        "    model = lgb.LGBMRegressor(learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                     max_depth=max_depth, subsample= subsample,\n",
        "                     colsample_bytree=colsample_bytree, num_leaves = num_leaves,\n",
        "                    min_child_samples=min_child_samples, subsample_for_bin=subsample_for_bin,\n",
        "                    reg_alpha=reg_alpha, reg_lambda = reg_lambda)\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    #mse = mean_squared_error(y_test, y_pred)\n",
        "    #r2 = r2_score(y_test, y_pred)\n",
        "    mape =  - mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    return mape"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aivFFzjtqowq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = BayesianOptimization(\n",
        "    f=lgb_hyper_param1,\n",
        "    pbounds=pbounds1,\n",
        "    random_state=2020,\n",
        ")"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPMf4umFqolH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "970c1b17-9c26-4c41-deae-fdbaca2e83b0"
      },
      "source": [
        "optimizer.maximize(init_points=3, n_iter=30, acq='ei')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample | subsam... |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-95.17   \u001b[0m | \u001b[0m 0.9959  \u001b[0m | \u001b[0m 0.2633  \u001b[0m | \u001b[0m 7.156   \u001b[0m | \u001b[0m 41.75   \u001b[0m | \u001b[0m 2.674e+0\u001b[0m | \u001b[0m 56.03   \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 3.254e+0\u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-92.1    \u001b[0m | \u001b[95m 0.7423  \u001b[0m | \u001b[95m 0.2296  \u001b[0m | \u001b[95m 10.78   \u001b[0m | \u001b[95m 48.45   \u001b[0m | \u001b[95m 2.682e+0\u001b[0m | \u001b[95m 110.0   \u001b[0m | \u001b[95m 0.6086  \u001b[0m | \u001b[95m 0.7246  \u001b[0m | \u001b[95m 0.5373  \u001b[0m | \u001b[95m 4.558e+0\u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-88.53   \u001b[0m | \u001b[95m 0.986   \u001b[0m | \u001b[95m 0.04983 \u001b[0m | \u001b[95m 8.111   \u001b[0m | \u001b[95m 98.05   \u001b[0m | \u001b[95m 3.007e+0\u001b[0m | \u001b[95m 110.1   \u001b[0m | \u001b[95m 0.5171  \u001b[0m | \u001b[95m 0.6824  \u001b[0m | \u001b[95m 0.5468  \u001b[0m | \u001b[95m 5.808e+0\u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-88.65   \u001b[0m | \u001b[0m 0.7887  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 7.562   \u001b[0m | \u001b[0m 83.16   \u001b[0m | \u001b[0m 3.974e+0\u001b[0m | \u001b[0m 142.2   \u001b[0m | \u001b[0m 0.5102  \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 0.7189  \u001b[0m | \u001b[0m 5.222e+0\u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-94.74   \u001b[0m | \u001b[0m 0.9985  \u001b[0m | \u001b[0m 0.2822  \u001b[0m | \u001b[0m 8.82    \u001b[0m | \u001b[0m 43.87   \u001b[0m | \u001b[0m 3.947e+0\u001b[0m | \u001b[0m 135.8   \u001b[0m | \u001b[0m 0.9332  \u001b[0m | \u001b[0m 0.8114  \u001b[0m | \u001b[0m 0.5241  \u001b[0m | \u001b[0m 5.513e+0\u001b[0m |\n",
            "| \u001b[95m 6       \u001b[0m | \u001b[95m-88.12   \u001b[0m | \u001b[95m 0.896   \u001b[0m | \u001b[95m 0.03541 \u001b[0m | \u001b[95m 10.22   \u001b[0m | \u001b[95m 89.92   \u001b[0m | \u001b[95m 2.473e+0\u001b[0m | \u001b[95m 84.35   \u001b[0m | \u001b[95m 0.9776  \u001b[0m | \u001b[95m 0.7417  \u001b[0m | \u001b[95m 0.7472  \u001b[0m | \u001b[95m 4.184e+0\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-94.98   \u001b[0m | \u001b[0m 0.9729  \u001b[0m | \u001b[0m 0.2943  \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 84.07   \u001b[0m | \u001b[0m 2.48e+03\u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 0.584   \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 0.6336  \u001b[0m | \u001b[0m 2.586e+0\u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-91.44   \u001b[0m | \u001b[0m 0.8803  \u001b[0m | \u001b[0m 0.05976 \u001b[0m | \u001b[0m-0.3307  \u001b[0m | \u001b[0m 38.82   \u001b[0m | \u001b[0m 3.571e+0\u001b[0m | \u001b[0m 68.47   \u001b[0m | \u001b[0m 0.6362  \u001b[0m | \u001b[0m 0.6211  \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 7.09e+04\u001b[0m |\n",
            "| \u001b[95m 9       \u001b[0m | \u001b[95m-86.72   \u001b[0m | \u001b[95m 0.7833  \u001b[0m | \u001b[95m 0.191   \u001b[0m | \u001b[95m 4.855   \u001b[0m | \u001b[95m 88.83   \u001b[0m | \u001b[95m 3.171e+0\u001b[0m | \u001b[95m 89.62   \u001b[0m | \u001b[95m 0.8894  \u001b[0m | \u001b[95m 0.8371  \u001b[0m | \u001b[95m 0.5127  \u001b[0m | \u001b[95m 3.123e+0\u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-88.51   \u001b[0m | \u001b[0m 0.7385  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 10.82   \u001b[0m | \u001b[0m 87.51   \u001b[0m | \u001b[0m 3.529e+0\u001b[0m | \u001b[0m 74.69   \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 0.5249  \u001b[0m | \u001b[0m 0.7904  \u001b[0m | \u001b[0m 4.624e+0\u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-88.01   \u001b[0m | \u001b[0m 0.7209  \u001b[0m | \u001b[0m 0.2446  \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 50.07   \u001b[0m | \u001b[0m 2.398e+0\u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 0.7949  \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 2.519e+0\u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-92.11   \u001b[0m | \u001b[0m 0.8265  \u001b[0m | \u001b[0m 0.2826  \u001b[0m | \u001b[0m-0.5166  \u001b[0m | \u001b[0m 35.61   \u001b[0m | \u001b[0m 2.672e+0\u001b[0m | \u001b[0m 73.27   \u001b[0m | \u001b[0m 0.6408  \u001b[0m | \u001b[0m 0.6039  \u001b[0m | \u001b[0m 0.6937  \u001b[0m | \u001b[0m 3.842e+0\u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-86.76   \u001b[0m | \u001b[0m 0.8558  \u001b[0m | \u001b[0m 0.01859 \u001b[0m | \u001b[0m 13.11   \u001b[0m | \u001b[0m 80.87   \u001b[0m | \u001b[0m 3.374e+0\u001b[0m | \u001b[0m 35.33   \u001b[0m | \u001b[0m 0.6684  \u001b[0m | \u001b[0m 0.5924  \u001b[0m | \u001b[0m 0.5179  \u001b[0m | \u001b[0m 7.828e+0\u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-91.96   \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 10.14   \u001b[0m | \u001b[0m 70.95   \u001b[0m | \u001b[0m 2.619e+0\u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 0.7303  \u001b[0m | \u001b[0m 0.5991  \u001b[0m | \u001b[0m 2.94e+04\u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-88.61   \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.2109  \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 43.13   \u001b[0m | \u001b[0m 3.66e+03\u001b[0m | \u001b[0m 41.2    \u001b[0m | \u001b[0m 0.9922  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 8.717e+0\u001b[0m |\n",
            "| \u001b[95m 16      \u001b[0m | \u001b[95m-86.23   \u001b[0m | \u001b[95m 0.9538  \u001b[0m | \u001b[95m 0.04709 \u001b[0m | \u001b[95m 4.946   \u001b[0m | \u001b[95m 85.72   \u001b[0m | \u001b[95m 3.307e+0\u001b[0m | \u001b[95m 66.71   \u001b[0m | \u001b[95m 0.8634  \u001b[0m | \u001b[95m 0.8334  \u001b[0m | \u001b[95m 0.7049  \u001b[0m | \u001b[95m 5.071e+0\u001b[0m |\n",
            "| \u001b[95m 17      \u001b[0m | \u001b[95m-85.78   \u001b[0m | \u001b[95m 0.9575  \u001b[0m | \u001b[95m 0.2769  \u001b[0m | \u001b[95m 9.521   \u001b[0m | \u001b[95m 64.14   \u001b[0m | \u001b[95m 2.868e+0\u001b[0m | \u001b[95m 128.6   \u001b[0m | \u001b[95m 0.7526  \u001b[0m | \u001b[95m 0.8566  \u001b[0m | \u001b[95m 0.7146  \u001b[0m | \u001b[95m 6.138e+0\u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-89.43   \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.01533 \u001b[0m | \u001b[0m 9.644   \u001b[0m | \u001b[0m 60.55   \u001b[0m | \u001b[0m 3.211e+0\u001b[0m | \u001b[0m 91.76   \u001b[0m | \u001b[0m 0.7785  \u001b[0m | \u001b[0m 0.7679  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 4.889e+0\u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-87.87   \u001b[0m | \u001b[0m 0.911   \u001b[0m | \u001b[0m 0.202   \u001b[0m | \u001b[0m-0.7607  \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 3.644e+0\u001b[0m | \u001b[0m 122.6   \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 8.2e+04 \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-89.74   \u001b[0m | \u001b[0m 0.9897  \u001b[0m | \u001b[0m 0.0439  \u001b[0m | \u001b[0m 4.446   \u001b[0m | \u001b[0m 81.76   \u001b[0m | \u001b[0m 2.889e+0\u001b[0m | \u001b[0m 85.92   \u001b[0m | \u001b[0m 0.9119  \u001b[0m | \u001b[0m 0.8953  \u001b[0m | \u001b[0m 0.714   \u001b[0m | \u001b[0m 7.844e+0\u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-94.16   \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.2201  \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 99.68   \u001b[0m | \u001b[0m 3.034e+0\u001b[0m | \u001b[0m 101.5   \u001b[0m | \u001b[0m 0.8568  \u001b[0m | \u001b[0m 0.7732  \u001b[0m | \u001b[0m 0.6008  \u001b[0m | \u001b[0m 2.995e+0\u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-89.91   \u001b[0m | \u001b[0m 0.8849  \u001b[0m | \u001b[0m 0.2147  \u001b[0m | \u001b[0m 14.14   \u001b[0m | \u001b[0m 68.96   \u001b[0m | \u001b[0m 2.929e+0\u001b[0m | \u001b[0m 65.37   \u001b[0m | \u001b[0m 0.8451  \u001b[0m | \u001b[0m 0.8433  \u001b[0m | \u001b[0m 0.6906  \u001b[0m | \u001b[0m 6.142e+0\u001b[0m |\n",
            "| \u001b[95m 23      \u001b[0m | \u001b[95m-85.01   \u001b[0m | \u001b[95m 0.961   \u001b[0m | \u001b[95m 0.2444  \u001b[0m | \u001b[95m 3.98    \u001b[0m | \u001b[95m 99.42   \u001b[0m | \u001b[95m 3.134e+0\u001b[0m | \u001b[95m 80.39   \u001b[0m | \u001b[95m 0.7884  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 0.7669  \u001b[0m | \u001b[95m 3.123e+0\u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-89.6    \u001b[0m | \u001b[0m 0.8709  \u001b[0m | \u001b[0m 0.07713 \u001b[0m | \u001b[0m 0.7592  \u001b[0m | \u001b[0m 77.67   \u001b[0m | \u001b[0m 3.317e+0\u001b[0m | \u001b[0m 100.6   \u001b[0m | \u001b[0m 0.6127  \u001b[0m | \u001b[0m 0.6955  \u001b[0m | \u001b[0m 0.7188  \u001b[0m | \u001b[0m 5.078e+0\u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-89.23   \u001b[0m | \u001b[0m 0.7167  \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 91.84   \u001b[0m | \u001b[0m 3.105e+0\u001b[0m | \u001b[0m 30.87   \u001b[0m | \u001b[0m 0.9063  \u001b[0m | \u001b[0m 0.7584  \u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 3.122e+0\u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-92.21   \u001b[0m | \u001b[0m 0.977   \u001b[0m | \u001b[0m 0.02805 \u001b[0m | \u001b[0m 13.73   \u001b[0m | \u001b[0m 39.63   \u001b[0m | \u001b[0m 2.9e+03 \u001b[0m | \u001b[0m 146.2   \u001b[0m | \u001b[0m 0.8924  \u001b[0m | \u001b[0m 0.6248  \u001b[0m | \u001b[0m 0.6081  \u001b[0m | \u001b[0m 6.137e+0\u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-92.52   \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 0.07523 \u001b[0m | \u001b[0m 11.26   \u001b[0m | \u001b[0m 30.4    \u001b[0m | \u001b[0m 2.77e+03\u001b[0m | \u001b[0m 137.0   \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 0.7673  \u001b[0m | \u001b[0m 0.569   \u001b[0m | \u001b[0m 6.258e+0\u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-90.89   \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 0.1489  \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 23.25   \u001b[0m | \u001b[0m 2.004e+0\u001b[0m | \u001b[0m 68.44   \u001b[0m | \u001b[0m 0.6688  \u001b[0m | \u001b[0m 0.7144  \u001b[0m | \u001b[0m 0.5852  \u001b[0m | \u001b[0m 6.118e+0\u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-87.61   \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 0.08599 \u001b[0m | \u001b[0m-0.2725  \u001b[0m | \u001b[0m 50.76   \u001b[0m | \u001b[0m 2.357e+0\u001b[0m | \u001b[0m 78.16   \u001b[0m | \u001b[0m 0.8355  \u001b[0m | \u001b[0m 0.6699  \u001b[0m | \u001b[0m 0.5988  \u001b[0m | \u001b[0m 2.517e+0\u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-88.66   \u001b[0m | \u001b[0m 0.7372  \u001b[0m | \u001b[0m 0.2142  \u001b[0m | \u001b[0m 7.928   \u001b[0m | \u001b[0m 22.05   \u001b[0m | \u001b[0m 2.217e+0\u001b[0m | \u001b[0m 140.6   \u001b[0m | \u001b[0m 0.9294  \u001b[0m | \u001b[0m 0.5706  \u001b[0m | \u001b[0m 0.7875  \u001b[0m | \u001b[0m 2.888e+0\u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-88.13   \u001b[0m | \u001b[0m 0.837   \u001b[0m | \u001b[0m 0.2226  \u001b[0m | \u001b[0m 8.696   \u001b[0m | \u001b[0m 81.75   \u001b[0m | \u001b[0m 2.695e+0\u001b[0m | \u001b[0m 148.5   \u001b[0m | \u001b[0m 0.8963  \u001b[0m | \u001b[0m 0.5565  \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 4.187e+0\u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-92.52   \u001b[0m | \u001b[0m 0.8253  \u001b[0m | \u001b[0m 0.1991  \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 78.35   \u001b[0m | \u001b[0m 3.354e+0\u001b[0m | \u001b[0m 126.2   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.7082  \u001b[0m | \u001b[0m 0.7388  \u001b[0m | \u001b[0m 9.24e+04\u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-92.95   \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.2615  \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 64.59   \u001b[0m | \u001b[0m 3.217e+0\u001b[0m | \u001b[0m 77.58   \u001b[0m | \u001b[0m 0.5029  \u001b[0m | \u001b[0m 0.8115  \u001b[0m | \u001b[0m 0.7888  \u001b[0m | \u001b[0m 6.375e+0\u001b[0m |\n",
            "=================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0L8KcCUqoQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "17f15665-6d2e-4134-a1f0-eb5fb7b7a410"
      },
      "source": [
        "optimizer.max"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'colsample_bytree': 0.9610223217284577,\n",
              "  'learning_rate': 0.24435226868650517,\n",
              "  'max_depth': 3.9799770831020034,\n",
              "  'min_child_samples': 99.42112225060113,\n",
              "  'n_estimators': 3134.2424133892073,\n",
              "  'num_leaves': 80.39202652725794,\n",
              "  'reg_alpha': 0.7884486336576992,\n",
              "  'reg_lambda': 0.8890709441502967,\n",
              "  'subsample': 0.7668867344992205,\n",
              "  'subsample_for_bin': 31225.01591263318},\n",
              " 'target': -85.00897774430823}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "494qB1ISqvVH",
        "colab_type": "text"
      },
      "source": [
        "{'params': {'colsample_bytree': 0.9610223217284577,\n",
        "  'learning_rate': 0.24435226868650517,\n",
        "  'max_depth': 3.9799770831020034,\n",
        "  'min_child_samples': 99.42112225060113,\n",
        "  'n_estimators': 3134.2424133892073,\n",
        "  'num_leaves': 80.39202652725794,\n",
        "  'reg_alpha': 0.7884486336576992,\n",
        "  'reg_lambda': 0.8890709441502967,\n",
        "  'subsample': 0.7668867344992205,\n",
        "  'subsample_for_bin': 31225.01591263318},\n",
        " 'target': -85.00897774430823}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXENYDrNqvsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.LGBMRegressor(learning_rate=optimizer.max['params']['learning_rate'], \n",
        "                          n_estimators=int(optimizer.max['params']['n_estimators']),\n",
        "                          num_leaves = int(optimizer.max['params']['num_leaves']),\n",
        "                          subsample = optimizer.max['params']['subsample'],\n",
        "                          subsample_for_bin = int(optimizer.max['params']['subsample_for_bin']), \n",
        "                          random_state=2020,\n",
        "                          colsample_bytree = optimizer.max['params']['colsample_bytree'],\n",
        "                          min_child_samples = int(optimizer.max['params']['min_child_samples']),\n",
        "                          max_depth = int(optimizer.max['params']['max_depth']),\n",
        "                          reg_alpha = optimizer.max['params']['reg_alpha'], \n",
        "                          reg_lambda = optimizer.max['params']['reg_lambda'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlZMoJ_eqhK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "lgbm_pred = model.predict(X_test)\n",
        "lgbm_pred_train = model.predict(X_train)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI-ETOh-qhFH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6fbabc3e-bf18-4e82-9c18-87c1e83517b4"
      },
      "source": [
        "mape_train = mean_absolute_percentage_error(np.exp(y_train), np.exp(lgbm_pred_train))\n",
        "mape_test = mean_absolute_percentage_error(np.exp(y_test), np.exp(lgbm_pred))\n",
        "\n",
        "print('MAPE => train: %.2f,   test: %.2f' %(mape_train, mape_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE => train: 32.38,   test: 43.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAKKTW0QqzdM",
        "colab_type": "text"
      },
      "source": [
        "High"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3gNoGuklYbOq",
        "colab": {}
      },
      "source": [
        "high_train=strat_train[strat_train['class_']==3]\n",
        "high_test=strat_test[strat_test['class_']==3]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5riDCnVfrbz9",
        "colab": {}
      },
      "source": [
        "high_train = high_train.drop(['class_','total'],axis =1)\n",
        "high_test = high_test.drop(['class_','total'],axis =1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CMbqgzFkrb0I",
        "colab": {}
      },
      "source": [
        "high_train = high_train[high_train.Y!=0]\n",
        "high_test = high_test[high_test.Y!=0]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNdz3ZZerb0L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2f808d13-410f-4433-d832-ae0d9b8d458a"
      },
      "source": [
        "print(high_train.shape)\n",
        "print(high_test.shape)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5656, 189)\n",
            "(1845, 189)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Jq2hqJ0rb0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0146718e-efd4-42b6-a832-b9c9d280f79b"
      },
      "source": [
        "X_train = high_train[high_train.columns.difference(['Y'])]\n",
        "y_train = np.log(high_train['Y'])\n",
        "X_test = high_test[high_test.columns.difference(['Y'])]\n",
        "y_test = np.log(high_test['Y'])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5656, 188) (5656,)\n",
            "(1845, 188) (1845,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyDJbF6DrY9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " pbounds2 = {'learning_rate' : (0.01, 0.3),\n",
        "            'n_estimators': (2000, 4000),\n",
        "            'num_leaves' : (30, 150),\n",
        "            'max_depth' : (-1, 15),\n",
        "            'colsample_bytree' : (0.7, 1),\n",
        "            'subsample' : (0.5, 0.8), \n",
        "            'min_child_samples': (20, 100),\n",
        "            'subsample_for_bin': (20000, 100000),\n",
        "            'reg_lambda' : (0.5,0.9), 'reg_alpha': (0.5,1.0)}"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-HfNL_irYz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lgb_hyper_param2(learning_rate, n_estimators, max_depth, \n",
        "                        subsample, colsample_bytree, num_leaves, \n",
        "                        min_child_samples, subsample_for_bin,\n",
        "                      reg_alpha, reg_lambda):\n",
        "    \n",
        "    max_depth = int(max_depth)\n",
        "    n_estimators = int(n_estimators)\n",
        "    min_child_samples = int(min_child_samples)\n",
        "    num_leaves = int(num_leaves)\n",
        "    subsample_for_bin = int(subsample_for_bin)\n",
        "\n",
        "    \n",
        "    model = lgb.LGBMRegressor(learning_rate=learning_rate, n_estimators=n_estimators,\n",
        "                     max_depth=max_depth, subsample= subsample,\n",
        "                     colsample_bytree=colsample_bytree, num_leaves = num_leaves,\n",
        "                    min_child_samples=min_child_samples, subsample_for_bin=subsample_for_bin,\n",
        "                    reg_alpha=reg_alpha, reg_lambda = reg_lambda)\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    \n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    #mse = mean_squared_error(y_test, y_pred)\n",
        "    #r2 = r2_score(y_test, y_pred)\n",
        "    mape =  - mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "    return mape"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsqlP2dWrYhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = BayesianOptimization(\n",
        "    f=lgb_hyper_param2,\n",
        "    pbounds=pbounds2,\n",
        "    random_state=2020,\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xl23u3DyYbOu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "7fd0d153-bd1f-4ac7-e0fc-f0918556eb94"
      },
      "source": [
        "optimizer.maximize(init_points=3, n_iter=30, acq='ei')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | reg_alpha | reg_la... | subsample | subsam... |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-141.6   \u001b[0m | \u001b[0m 0.9959  \u001b[0m | \u001b[0m 0.2633  \u001b[0m | \u001b[0m 7.156   \u001b[0m | \u001b[0m 41.75   \u001b[0m | \u001b[0m 2.674e+0\u001b[0m | \u001b[0m 56.03   \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 3.254e+0\u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-143.0   \u001b[0m | \u001b[0m 0.7423  \u001b[0m | \u001b[0m 0.2296  \u001b[0m | \u001b[0m 10.78   \u001b[0m | \u001b[0m 48.45   \u001b[0m | \u001b[0m 2.682e+0\u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.6086  \u001b[0m | \u001b[0m 0.7246  \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 4.558e+0\u001b[0m |\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m-137.2   \u001b[0m | \u001b[95m 0.986   \u001b[0m | \u001b[95m 0.04983 \u001b[0m | \u001b[95m 8.111   \u001b[0m | \u001b[95m 98.05   \u001b[0m | \u001b[95m 3.007e+0\u001b[0m | \u001b[95m 110.1   \u001b[0m | \u001b[95m 0.5171  \u001b[0m | \u001b[95m 0.6824  \u001b[0m | \u001b[95m 0.5468  \u001b[0m | \u001b[95m 5.808e+0\u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-141.4   \u001b[0m | \u001b[0m 0.7887  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 7.562   \u001b[0m | \u001b[0m 83.16   \u001b[0m | \u001b[0m 3.974e+0\u001b[0m | \u001b[0m 142.2   \u001b[0m | \u001b[0m 0.5102  \u001b[0m | \u001b[0m 0.6505  \u001b[0m | \u001b[0m 0.7189  \u001b[0m | \u001b[0m 5.222e+0\u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-140.2   \u001b[0m | \u001b[0m 0.9499  \u001b[0m | \u001b[0m 0.02346 \u001b[0m | \u001b[0m 12.4    \u001b[0m | \u001b[0m 43.76   \u001b[0m | \u001b[0m 2.177e+0\u001b[0m | \u001b[0m 70.7    \u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.8529  \u001b[0m | \u001b[0m 0.6001  \u001b[0m | \u001b[0m 3.65e+04\u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-138.6   \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 0.03541 \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 89.92   \u001b[0m | \u001b[0m 2.473e+0\u001b[0m | \u001b[0m 84.35   \u001b[0m | \u001b[0m 0.9776  \u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.7472  \u001b[0m | \u001b[0m 4.184e+0\u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-142.5   \u001b[0m | \u001b[0m 0.9729  \u001b[0m | \u001b[0m 0.2943  \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 84.07   \u001b[0m | \u001b[0m 2.48e+03\u001b[0m | \u001b[0m 55.24   \u001b[0m | \u001b[0m 0.584   \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 0.6336  \u001b[0m | \u001b[0m 2.586e+0\u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-140.1   \u001b[0m | \u001b[0m 0.8803  \u001b[0m | \u001b[0m 0.05976 \u001b[0m | \u001b[0m-0.3307  \u001b[0m | \u001b[0m 38.82   \u001b[0m | \u001b[0m 3.571e+0\u001b[0m | \u001b[0m 68.47   \u001b[0m | \u001b[0m 0.6362  \u001b[0m | \u001b[0m 0.6211  \u001b[0m | \u001b[0m 0.7843  \u001b[0m | \u001b[0m 7.09e+04\u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-138.5   \u001b[0m | \u001b[0m 0.7833  \u001b[0m | \u001b[0m 0.191   \u001b[0m | \u001b[0m 4.855   \u001b[0m | \u001b[0m 88.83   \u001b[0m | \u001b[0m 3.171e+0\u001b[0m | \u001b[0m 89.62   \u001b[0m | \u001b[0m 0.8894  \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.5127  \u001b[0m | \u001b[0m 3.123e+0\u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-144.0   \u001b[0m | \u001b[0m 0.7385  \u001b[0m | \u001b[0m 0.1715  \u001b[0m | \u001b[0m 10.82   \u001b[0m | \u001b[0m 87.51   \u001b[0m | \u001b[0m 3.529e+0\u001b[0m | \u001b[0m 74.69   \u001b[0m | \u001b[0m 0.6035  \u001b[0m | \u001b[0m 0.5249  \u001b[0m | \u001b[0m 0.7904  \u001b[0m | \u001b[0m 4.624e+0\u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-140.3   \u001b[0m | \u001b[0m 0.7209  \u001b[0m | \u001b[0m 0.2446  \u001b[0m | \u001b[0m 3.671   \u001b[0m | \u001b[0m 50.07   \u001b[0m | \u001b[0m 2.398e+0\u001b[0m | \u001b[0m 61.62   \u001b[0m | \u001b[0m 0.7949  \u001b[0m | \u001b[0m 0.7081  \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 2.519e+0\u001b[0m |\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m-135.0   \u001b[0m | \u001b[95m 0.8265  \u001b[0m | \u001b[95m 0.2826  \u001b[0m | \u001b[95m-0.5166  \u001b[0m | \u001b[95m 35.61   \u001b[0m | \u001b[95m 2.672e+0\u001b[0m | \u001b[95m 73.27   \u001b[0m | \u001b[95m 0.6408  \u001b[0m | \u001b[95m 0.6039  \u001b[0m | \u001b[95m 0.6937  \u001b[0m | \u001b[95m 3.842e+0\u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-141.0   \u001b[0m | \u001b[0m 0.7122  \u001b[0m | \u001b[0m 0.2014  \u001b[0m | \u001b[0m 10.46   \u001b[0m | \u001b[0m 92.23   \u001b[0m | \u001b[0m 2.776e+0\u001b[0m | \u001b[0m 131.0   \u001b[0m | \u001b[0m 0.8164  \u001b[0m | \u001b[0m 0.7259  \u001b[0m | \u001b[0m 0.7216  \u001b[0m | \u001b[0m 3.838e+0\u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-141.5   \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 0.1545  \u001b[0m | \u001b[0m 10.14   \u001b[0m | \u001b[0m 70.95   \u001b[0m | \u001b[0m 2.619e+0\u001b[0m | \u001b[0m 118.1   \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 0.7303  \u001b[0m | \u001b[0m 0.5991  \u001b[0m | \u001b[0m 2.94e+04\u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-142.0   \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.2109  \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 43.13   \u001b[0m | \u001b[0m 3.66e+03\u001b[0m | \u001b[0m 41.2    \u001b[0m | \u001b[0m 0.9922  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 0.5431  \u001b[0m | \u001b[0m 8.717e+0\u001b[0m |\n",
            "| \u001b[95m 16      \u001b[0m | \u001b[95m-131.1   \u001b[0m | \u001b[95m 0.9538  \u001b[0m | \u001b[95m 0.04709 \u001b[0m | \u001b[95m 4.946   \u001b[0m | \u001b[95m 85.72   \u001b[0m | \u001b[95m 3.307e+0\u001b[0m | \u001b[95m 66.71   \u001b[0m | \u001b[95m 0.8634  \u001b[0m | \u001b[95m 0.8334  \u001b[0m | \u001b[95m 0.7049  \u001b[0m | \u001b[95m 5.071e+0\u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-139.1   \u001b[0m | \u001b[0m 0.9575  \u001b[0m | \u001b[0m 0.2769  \u001b[0m | \u001b[0m 9.521   \u001b[0m | \u001b[0m 64.14   \u001b[0m | \u001b[0m 2.868e+0\u001b[0m | \u001b[0m 128.6   \u001b[0m | \u001b[0m 0.7526  \u001b[0m | \u001b[0m 0.8566  \u001b[0m | \u001b[0m 0.7146  \u001b[0m | \u001b[0m 6.138e+0\u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-136.7   \u001b[0m | \u001b[0m 0.7439  \u001b[0m | \u001b[0m 0.01533 \u001b[0m | \u001b[0m 9.644   \u001b[0m | \u001b[0m 60.55   \u001b[0m | \u001b[0m 3.211e+0\u001b[0m | \u001b[0m 91.76   \u001b[0m | \u001b[0m 0.7785  \u001b[0m | \u001b[0m 0.7679  \u001b[0m | \u001b[0m 0.7936  \u001b[0m | \u001b[0m 4.889e+0\u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-139.9   \u001b[0m | \u001b[0m 0.911   \u001b[0m | \u001b[0m 0.202   \u001b[0m | \u001b[0m-0.7607  \u001b[0m | \u001b[0m 91.72   \u001b[0m | \u001b[0m 3.644e+0\u001b[0m | \u001b[0m 122.6   \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 8.2e+04 \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-131.3   \u001b[0m | \u001b[0m 0.9897  \u001b[0m | \u001b[0m 0.0439  \u001b[0m | \u001b[0m 4.446   \u001b[0m | \u001b[0m 81.76   \u001b[0m | \u001b[0m 2.889e+0\u001b[0m | \u001b[0m 85.92   \u001b[0m | \u001b[0m 0.9119  \u001b[0m | \u001b[0m 0.8953  \u001b[0m | \u001b[0m 0.714   \u001b[0m | \u001b[0m 7.844e+0\u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-141.2   \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.2201  \u001b[0m | \u001b[0m 13.0    \u001b[0m | \u001b[0m 99.68   \u001b[0m | \u001b[0m 3.034e+0\u001b[0m | \u001b[0m 101.5   \u001b[0m | \u001b[0m 0.8568  \u001b[0m | \u001b[0m 0.7732  \u001b[0m | \u001b[0m 0.6008  \u001b[0m | \u001b[0m 2.995e+0\u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-140.3   \u001b[0m | \u001b[0m 0.9571  \u001b[0m | \u001b[0m 0.05958 \u001b[0m | \u001b[0m 6.33    \u001b[0m | \u001b[0m 58.33   \u001b[0m | \u001b[0m 3.378e+0\u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 0.7372  \u001b[0m | \u001b[0m 0.6497  \u001b[0m | \u001b[0m 0.7205  \u001b[0m | \u001b[0m 5.085e+0\u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-142.0   \u001b[0m | \u001b[0m 0.7288  \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 13.84   \u001b[0m | \u001b[0m 78.77   \u001b[0m | \u001b[0m 2.716e+0\u001b[0m | \u001b[0m 81.57   \u001b[0m | \u001b[0m 0.8412  \u001b[0m | \u001b[0m 0.6944  \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 9.575e+0\u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-143.8   \u001b[0m | \u001b[0m 0.7426  \u001b[0m | \u001b[0m 0.277   \u001b[0m | \u001b[0m-0.2837  \u001b[0m | \u001b[0m 56.8    \u001b[0m | \u001b[0m 3.275e+0\u001b[0m | \u001b[0m 140.2   \u001b[0m | \u001b[0m 0.6114  \u001b[0m | \u001b[0m 0.6815  \u001b[0m | \u001b[0m 0.7274  \u001b[0m | \u001b[0m 5.663e+0\u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-137.5   \u001b[0m | \u001b[0m 0.771   \u001b[0m | \u001b[0m 0.2831  \u001b[0m | \u001b[0m 13.96   \u001b[0m | \u001b[0m 24.5    \u001b[0m | \u001b[0m 3.898e+0\u001b[0m | \u001b[0m 128.0   \u001b[0m | \u001b[0m 0.8307  \u001b[0m | \u001b[0m 0.7816  \u001b[0m | \u001b[0m 0.7862  \u001b[0m | \u001b[0m 2.821e+0\u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-139.9   \u001b[0m | \u001b[0m 0.9884  \u001b[0m | \u001b[0m 0.051   \u001b[0m | \u001b[0m 6.18    \u001b[0m | \u001b[0m 24.72   \u001b[0m | \u001b[0m 2.342e+0\u001b[0m | \u001b[0m 127.7   \u001b[0m | \u001b[0m 0.8701  \u001b[0m | \u001b[0m 0.8594  \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 7.65e+04\u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-137.8   \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 0.07523 \u001b[0m | \u001b[0m 11.26   \u001b[0m | \u001b[0m 30.4    \u001b[0m | \u001b[0m 2.77e+03\u001b[0m | \u001b[0m 137.0   \u001b[0m | \u001b[0m 0.6744  \u001b[0m | \u001b[0m 0.7673  \u001b[0m | \u001b[0m 0.569   \u001b[0m | \u001b[0m 6.258e+0\u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-144.1   \u001b[0m | \u001b[0m 0.9712  \u001b[0m | \u001b[0m 0.1489  \u001b[0m | \u001b[0m 14.29   \u001b[0m | \u001b[0m 23.25   \u001b[0m | \u001b[0m 2.004e+0\u001b[0m | \u001b[0m 68.44   \u001b[0m | \u001b[0m 0.6688  \u001b[0m | \u001b[0m 0.7144  \u001b[0m | \u001b[0m 0.5852  \u001b[0m | \u001b[0m 6.118e+0\u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-142.9   \u001b[0m | \u001b[0m 0.7171  \u001b[0m | \u001b[0m 0.2345  \u001b[0m | \u001b[0m 3.395   \u001b[0m | \u001b[0m 26.44   \u001b[0m | \u001b[0m 3.088e+0\u001b[0m | \u001b[0m 119.9   \u001b[0m | \u001b[0m 0.8607  \u001b[0m | \u001b[0m 0.8311  \u001b[0m | \u001b[0m 0.7201  \u001b[0m | \u001b[0m 4.575e+0\u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-135.3   \u001b[0m | \u001b[0m 0.7459  \u001b[0m | \u001b[0m 0.1686  \u001b[0m | \u001b[0m 2.159   \u001b[0m | \u001b[0m 27.36   \u001b[0m | \u001b[0m 2.666e+0\u001b[0m | \u001b[0m 62.22   \u001b[0m | \u001b[0m 0.7097  \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 0.7204  \u001b[0m | \u001b[0m 3.842e+0\u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-144.3   \u001b[0m | \u001b[0m 0.8259  \u001b[0m | \u001b[0m 0.2283  \u001b[0m | \u001b[0m 12.01   \u001b[0m | \u001b[0m 37.25   \u001b[0m | \u001b[0m 2.923e+0\u001b[0m | \u001b[0m 82.43   \u001b[0m | \u001b[0m 0.6891  \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.7753  \u001b[0m | \u001b[0m 7.848e+0\u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-146.0   \u001b[0m | \u001b[0m 0.8253  \u001b[0m | \u001b[0m 0.1991  \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 78.35   \u001b[0m | \u001b[0m 3.354e+0\u001b[0m | \u001b[0m 126.2   \u001b[0m | \u001b[0m 0.9648  \u001b[0m | \u001b[0m 0.7082  \u001b[0m | \u001b[0m 0.7388  \u001b[0m | \u001b[0m 9.24e+04\u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-145.0   \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.2615  \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 64.59   \u001b[0m | \u001b[0m 3.217e+0\u001b[0m | \u001b[0m 77.58   \u001b[0m | \u001b[0m 0.5029  \u001b[0m | \u001b[0m 0.8115  \u001b[0m | \u001b[0m 0.7888  \u001b[0m | \u001b[0m 6.375e+0\u001b[0m |\n",
            "=================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2eTZ6NnsvwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "3f8c652e-288c-4d14-c571-ad71523dfaee"
      },
      "source": [
        "optimizer.max"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'colsample_bytree': 0.9538482424001378,\n",
              "  'learning_rate': 0.047088127373434034,\n",
              "  'max_depth': 4.946227392443182,\n",
              "  'min_child_samples': 85.71579118441096,\n",
              "  'n_estimators': 3306.9232274896613,\n",
              "  'num_leaves': 66.71052458584967,\n",
              "  'reg_alpha': 0.8634226851807956,\n",
              "  'reg_lambda': 0.8334044312815695,\n",
              "  'subsample': 0.7049497992030136,\n",
              "  'subsample_for_bin': 50708.46245764874},\n",
              " 'target': -131.11328083960842}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJuPOeBsy2U",
        "colab_type": "text"
      },
      "source": [
        "{'params': {'colsample_bytree': 0.9538482424001378,\n",
        "  'learning_rate': 0.047088127373434034,\n",
        "  'max_depth': 4.946227392443182,\n",
        "  'min_child_samples': 85.71579118441096,\n",
        "  'n_estimators': 3306.9232274896613,\n",
        "  'num_leaves': 66.71052458584967,\n",
        "  'reg_alpha': 0.8634226851807956,\n",
        "  'reg_lambda': 0.8334044312815695,\n",
        "  'subsample': 0.7049497992030136,\n",
        "  'subsample_for_bin': 50708.46245764874},\n",
        " 'target': -131.11328083960842}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op8Y3pPusvuP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = lgb.LGBMRegressor(learning_rate=optimizer.max['params']['learning_rate'], \n",
        "                          n_estimators=int(optimizer.max['params']['n_estimators']),\n",
        "                          num_leaves = int(optimizer.max['params']['num_leaves']),\n",
        "                          subsample = optimizer.max['params']['subsample'],\n",
        "                          subsample_for_bin = int(optimizer.max['params']['subsample_for_bin']), \n",
        "                          random_state=2020,\n",
        "                          colsample_bytree = optimizer.max['params']['colsample_bytree'],\n",
        "                          min_child_samples = int(optimizer.max['params']['min_child_samples']),\n",
        "                          max_depth = int(optimizer.max['params']['max_depth']),\n",
        "                          reg_alpha = optimizer.max['params']['reg_alpha'], \n",
        "                          reg_lambda = optimizer.max['params']['reg_lambda'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsdg5dUasvq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "lgbm_pred = model.predict(X_test)\n",
        "lgbm_pred_train = model.predict(X_train)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLt6odOsvom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5af24168-f689-43d7-ec6f-584aa2fe88ee"
      },
      "source": [
        "mape_train = mean_absolute_percentage_error(np.exp(y_train), np.exp(lgbm_pred_train))\n",
        "mape_test = mean_absolute_percentage_error(np.exp(y_test), np.exp(lgbm_pred))\n",
        "\n",
        "print('MAPE => train: %.2f,   test: %.2f' %(mape_train, mape_test))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAPE => train: 37.76,   test: 54.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6Mzovkdsvls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df5cfbf0-d218-458d-cc1d-019083c54588"
      },
      "source": [
        "(29*2011 + 43.13*4975 + 54.65*1845) / (2011+4975+1845)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42.3191031593251"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    }
  ]
}